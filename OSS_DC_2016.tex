%%%%%%%%%%%%%%%%%%%%%%%%%% author.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample root file for your contribution to an IFIP volume
% published at Springer
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%%%%%%%%%% Springer-Verlag %%%%%%%%%%%%%%%%%%%%%%%%%%


% RECOMMENDED %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[ifip]{svmult}

% choose options for [] as required from the list
% in the Reference Guide, Sect. 2.2
\usepackage{epsfig} 
\usepackage{makeidx}         % allows index generation
\usepackage{graphicx}        % standard LaTeX graphics tool
                             % when including figure files
\usepackage{multicol}        % used for the two-column index
\usepackage[bottom]{footmisc}% places footnotes at page bottom
% etc.
% see the list of further useful packages
% in the Reference Guide, Sects. 2.3, 3.1-3.3

\makeindex             % used for the subject index
                       % please use the style sprmidx.sty with
                       % your makeindex program


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title*{Quantitative analysis of performance in key parameter of code review - Defects Individuation.}
%code review in software development in cloud-based system }
% Use \titlerunning{Short Title} for an abbreviated version of
% your contribution title if the original one is too long
\author{Dorealda Dalipaj\inst{1}}
% Use \authorrunning{Short Title} for an abbreviated version of
% your contribution title if the original one is too long
\institute{University Rey Juan Carlos, Madrid.
\texttt{dorealda.dalipaj@urjc.es}}
%
% Use the package "url.sty" to avoid
% problems with special characters
% used in your e-mail or web address
%
\maketitle

\textbf{\textit{Abstract -}} Code review is a well-established and cost-effective way to find defects, employed both in industrial and open source contexts. 
Today code review is tool assisted, like from Bug tracking systems that were developed to guide maintenance activities of 
software developers. Thus today it results time efficient and more lightweight compared to the early software inspections 
performed in the 80s. Finding and removing defects close to their point of injection remains the main motivation and a key parameter
for review. 
However, different studies (\cite{contribution1}, \cite{contribution9}, \cite{contribution20} ) had shown that code review is not performing as expected. 
They argued that the performance of code review 
was quite low and that the actual outcome of code review in finding errors was less than expected. Furthermore, another study 
\cite{contribution10}
argues that, as many software programs 
rely on bug reports to correct software errors in maintenance activities, developers spend much time to identify these bug reports. 
Thus, the aim of this study is to bring evidence by quantifying the performance of the very key parameter of code review: individuation of bugs.
We focus our case study on a cloud computing software, Open Stack \cite{contribution11}. 
A developer can contribute to its source code repository using the Launchpad Bugtracking \cite{contribution12} and 
Gerrit Code Review \cite{contribution13}. First, from Launchpad, we individuate the bug reports that are actually describing a defect, 
and extracted the needed information to bring statistical evidence on the number of defects that are individuated in Open Stack through the 
years. Second, we compare the first results to the total number of issues reported, grouped by their different types, 
to have proof of the rate at which the defects are discovered. And last we bring empirical evidence on the effort spent by developers, 
by means of time, to carry out the defect individuation process.

\section{Introduction}
\label{sec:1}
% Always give a unique label
% and use \ref{<label>} for cross-references
% and \cite{<label>} for bibliographic references
% use \sectionmark{}
% to alter or adjust the section heading in the running head

Code review, sometimes referred as peer review, is an activity in which people, other than the author of a software deliverable, 
examine it for defects and improvement opportunities.
Code review is characterized \textit{ as a systematic approach to examine a product in detail, 
using a predefined sequence of steps to determine if the product is fit for its intended use}
\cite{contribution14}. It is considered one of the most powerful software quality tools available. 


There have been different ways of performing defect detenction since its beginning up to nowadays. The formal review or inspection 
according to Fanagan \cite{contribution15} approach required the conduction of an inspection meeting for actually finding of 
defects. Different controlled experiments showed that there were no significant differeneces in the total number of defects found 
when comparing meeting-based with meeting-less-based inspections \cite{contribution17}, \cite{contribution18}. Other 
studies \cite{contribution19} were carried out and proved that more defects were identified with meeting-less-based approaches. 
As a result a wide range of mechanisms and techniques of code review were developed. From static analysis 
\cite{contribution3} \cite{contribution4} \cite{contribution5}, which examines the code in 
the absence of input data and without running the code and is tool based, to modern code review 
\cite{contribution6} \cite{contribution7} \cite{contribution8}, which aligning with the distributed 
nature of many projects is asynchronous and frequently supporting geographically distributed reviewers. Because of their many uses 
and benefits, code reviews are a standard part of the modern software engineering workflow.
\\ \\
Although it is generally accepted that quality in software remains a challenge due to defects presence. A major quality issue with 
software is that defects are a byproduct of the complex development process and the ability to develop defect free software 
remains a big challenge for the software community. 
It is possible to improve the quality of software product by injecting fewer defects or by identifying and 
removing defects injected. It is also generally accepted that performance of software review is affected by several factors of the 
defect detection process. Code review performance is associated with the effort spent to carry out the process and the number of 
defects found. 
\\ \\A wide set of empirical studies and new approaches have been proposed to understand and improve the review process since it 
was introduced by Fagan \cite{contribution15}. Sources of process variability range from structure (how steps of the inspection 
are organized), inspection inputs(reviewer ability and product quality), 
techniques applied to defect identification that define how each step is carried out), 
context and tool support \cite{contribution16}. Most empirical studies try to assess the impact of specific process settings on performance. 
A controlled experiment by Johnson and Tjahjono \cite{contribution17} showed that \textit{total defects identified, effort spent in the 
process, false positive defects, duplicates} are fundamental variables to analyse when controlling the performance of code review. 

\section{Discussion}
\label{sec:2}


%Static analysis examines code in 
%the absence of input data and without running the code, and can
%detect potential security violations (e.g., SQL injection), runtime errors (e.g., dereferencing a null pointer) and logical
%inconsistencies (e.g., a conditional test that cannot possibly be true). A growing number of projects and companies are concerned about 
%individuating bugs in their code and they are making this process part of their standard build and testing system. 
%According to \cite{contribution2}, Google has incorporated FindBugs into their standard testing and code review process, 
%and has fixed more than 1,000 issues in their internal code base identified by the tool.
%More powerful tools \cite{contribution3}, \cite{contribution4}, \cite{contribution5}, evaluate software in the
%abstract, without executing them or considering a specific input. It has become fairly clear that static analysis
%tools can find important defects in software.

Although code review is used in software engineering primarily for finding defects, severeal studies argue that they often 
do not find functionality defects.
\\ \\
Microsoft develops software in diverse domains, from high end server enterprise data management solutions such
as SQL Server to mobile phone applications and smart phone apps to search engines. Over the past two years, 
a common tool for code review, Code Flow, has achieved wide-spread adoption at Microsoft. 
The functionality of CodeFlow is similar to other review tools such Mondrian \cite{contribution6} (adopted at Google), Phabricator 
\cite{contribution7} (adopted at Facebook) or open-source Gerrit \cite{contribution8}.
Two studies where conducted at Microsoft on code review process.

The first study (\cite{contribution9}) took place with professional developers, testers, and managers at Microsoft. 
The results show that, although the top motivation driving code reviews is finding defects, the practice and the 
actual outcomes are less about finding errors than expected: Defect related comments comprise a small proportion, only 14\%, 
and mainly cover small logical low-level issues.
The second study conducted at Microsoft \cite{contribution20} stated that code review do not find bugs. They found that only about 
15\% of the comments provided by reviewers indicate a possible defect, much less functionallity issues that should block a 
code submission. 
\\ \\
Another empirical study on the effectiveness of security code review \cite{contribution1}, conducted an experiment on 30 developers. They 
conducted manual code review of a small web application. The web application supplied to the developers had seven known vulnerabilities. 
Their findings concluded that none of the subjects found all confirmed vulnerabilities (they were able to find only 5 out of 7) 
and that reports of false vulnerabilities were significantly correlated with reports of valid vulnerabilities.
\\ \\
A different experiment \cite{contribution10} argued that in large scale software programs developers spend much time to 
identify the bug reports (mainly due to the excessive number of duplicate bug reports).
\\ \\
Keeping in mind the above discussion we did this questions:
\\
1. Are all the code review tools performing a lame number of defects detection?
With the abundance of data coming from the engineering systems and having a diverse set of projects to observe 
\cite{contribution12} \cite{contribution13}, we ask 
if there is any code review providing more value than the others?
\\
2. What is the actual amount of time that developers take in individuating defects?
\\
\\
\\
\textit{Work in Progress...}

%\subsection{Subsection Heading}
%\label{sec:3}
%Your text goes here.

%\begin{equation}
%\vec{a}\times\vec{b}=\vec{c}
%\end{equation}

%\subsubsection{Subsubsection Heading}
%See Sect.~\ref{sec:1}.

%\paragraph{Paragraph Heading} %
%Your text goes here.

%\subparagraph{Subparagraph Heading.} Your text goes here.%
%
%\index{paragraph}
% Use the \index{} command to code your index words
%
% For tables use
%
%\begin{table}
%\centering
%\caption{Please write your table caption here}
%\label{tab:1}       % Give a unique label
%
% For LaTeX tables use
%
%\begin{tabular}{lll}
%\hline\noalign{\smallskip}
%first & second & third  \\
%\noalign{\smallskip}\hline\noalign{\smallskip}
%number & number & number \\
%number & number & number \\
%\noalign{\smallskip}\hline
%\end{tabular}
%\end{table}
%
%
% For figures use
%
%\begin{figure}
%\centering
% Use the relevant command for your figure-insertion program
% to insert the figure file.
% For example, with the option graphicx use
%\includegraphics[height=4cm]{figure.eps}
%
%\caption{Please write your figure caption here}
%\label{fig:1}       % Give a unique label
%\end{figure}
%
% For built-in environments use
%
%\begin{theorem}
%Theorem text\footnote{Footnote} goes here.
%\end{theorem}
%
% or
%
%\begin{lemma}
%Lemma text goes here.
%\end{lemma}
%
%
% BibTeX users please use
% \bibliographystyle{}
% \bibliography{}
%
% Non-BibTeX users please follow the syntax
% the syntax of "referenc.tex" for your own citations
\input{referenc}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\printindex
\end{document}





